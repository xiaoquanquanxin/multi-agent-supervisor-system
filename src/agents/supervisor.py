from typing import Literal
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from langgraph.types import Command

# Simplified imports without src
from ..agent_types.state import AgentState
from ..config.settings import SUPERVISOR_MODEL, SUPERVISOR_TEMPERATURE

def create_supervisor_agent():
    llm = ChatOpenAI(
        model=SUPERVISOR_MODEL,
        temperature=SUPERVISOR_TEMPERATURE
    )
    
    system_prompt = """æ‚¨æ˜¯ä¸€ä¸ªåè°ƒå›¾åƒå¤„ç†ä»»åŠ¡çš„ç›‘ç£è€…æ™ºèƒ½ä½“ã€‚
    æ ¹æ®ç”¨æˆ·çš„è¯·æ±‚å’Œå½“å‰çŠ¶æ€ï¼Œç¡®å®šä¸‹ä¸€ä¸ªåº”è¯¥æ‰§è¡Œçš„ä»»åŠ¡ã€‚
    
    å¯ç”¨ä»»åŠ¡ï¼š
    1. image_generation - å½“ç”¨æˆ·éœ€è¦åˆ›å»ºæ–°å›¾åƒæ—¶
    2. text_overlay - å½“éœ€è¦åœ¨å›¾åƒä¸Šæ·»åŠ æ–‡æœ¬æ—¶
    3. background_removal - å½“éœ€è¦ä»å›¾åƒä¸­ç§»é™¤èƒŒæ™¯æ—¶
    
    è§„åˆ™ï¼š
    - æŒ‰é¡ºåºå¤„ç†ä»»åŠ¡ï¼Œç›´åˆ°æ‰€æœ‰è¯·æ±‚çš„æ“ä½œéƒ½å®Œæˆ
    - å¦‚æœè¯·æ±‚æåˆ°åˆ›å»º/ç”Ÿæˆå›¾åƒï¼Œä» 'image_generation' å¼€å§‹
    - åœ¨å›¾åƒç”Ÿæˆåï¼Œå¦‚æœè¯·æ±‚äº†æ–‡æœ¬/æ ‡é¢˜ï¼Œä½¿ç”¨ 'text_overlay'
    - å¦‚æœè¯·æ±‚æåˆ°ç§»é™¤/åˆ é™¤èƒŒæ™¯ï¼Œä½¿ç”¨ 'background_removal'
    - åªæœ‰åœ¨æ‰€æœ‰è¯·æ±‚çš„ä»»åŠ¡éƒ½å®Œæˆæ—¶æ‰å›å¤ '__end__'
    - åœ¨å†³å®šä¸‹ä¸€ä¸ªä»»åŠ¡æ—¶ï¼Œè¦åŒæ—¶è€ƒè™‘åŸå§‹è¯·æ±‚å’Œå½“å‰ä»»åŠ¡çŠ¶æ€
    
    ç¤ºä¾‹åºåˆ—ï¼š
    - "ç”Ÿæˆä¸€å¼ å›¾ç‰‡å¹¶æ·»åŠ æ–‡å­—" â†’ image_generation â†’ text_overlay â†’ __end__
    - "åˆ›å»ºä¸€å¼ å›¾ç‰‡ï¼Œç§»é™¤èƒŒæ™¯ï¼Œæ·»åŠ æ–‡å­—" â†’ image_generation â†’ background_removal â†’ text_overlay â†’ __end__
    """

    def supervisor_agent(state: AgentState) -> Command[Literal["image_generation", "text_overlay", "background_removal", "__end__"]]:
        print("\nğŸ¯ ç›‘ç£è€…æ™ºèƒ½ä½“ï¼šå†³å®šä¸‹ä¸€ä¸ªä»»åŠ¡...")
        
        # Get the initial request if this is the first run
        messages = state["messages"]
        user_request = messages[0]["content"] if isinstance(messages[0], dict) else messages[0].content
        
        # Use LLM to decide next task
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"""
            åŸå§‹è¯·æ±‚ï¼š {user_request}
            å½“å‰ä»»åŠ¡ï¼š {state["current_task"]}
            
            ä¸‹ä¸€ä¸ªä»»åŠ¡åº”è¯¥æ˜¯ä»€ä¹ˆï¼Ÿ
            """)
        ]
        
        response = llm.invoke(messages).content
        
        # Parse the response to get the next task
        if "image_generation" in response.lower():
            next_agent = "image_generation"
        elif "text_overlay" in response.lower():
            next_agent = "text_overlay"
        elif "background_removal" in response.lower():
            next_agent = "background_removal"
        else:
            next_agent = "__end__"
        
        print(f"â¡ï¸ ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“ï¼š {next_agent}")
        
        return Command(
            goto=next_agent,
            update={
                "next_agent": next_agent,
                "current_task": next_agent,
                "messages": state["messages"] + [
                    {"role": "system", "content": f"ç›‘ç£è€…ï¼šè·¯ç”±åˆ° {next_agent}"}
                ]
            }
        )
    
    return supervisor_agent 